# Fabric-Lite User Manual

**Your Complete Guide to Local AI Tools** ğŸ¯

---

## Getting Started - Your First AI Conversation

### ğŸš€ Quick Start (3 Minutes)

```bash
# Step 1: Get the project
git clone https://github.com/rice0649/fabric-lite
cd fabric-lite

# Step 2: One-command setup
curl -fsSL https://raw.githubusercontent.com/rice0649/fabric-lite/main/forgiving-setup.sh | bash

# Step 3: Your first AI conversation!
./bin/fabric-lite run "Hello AI assistant, can you help me understand how you work?" --provider ollama
```

**ğŸ‰ Congratulations! You just had your first local AI conversation!**

---

## What Makes This Special?

### ğŸ”’ Your Privacy, Your Control
- **No Cloud Required**: Everything happens on your computer
- **Your Data Stays Private**: No internet uploads or tracking
- **You're in Charge**: Use any AI model you prefer
- **Offline Capable**: Works without internet once models are downloaded

### ğŸ§  AI That Thinks Like You
- **Natural Conversations**: Just talk to it like a person
- **Context Aware**: Remembers what you're working on
- **Multi-Talented**: Can write, summarize, explain, and create
- **Pattern Smart**: Uses templates for specific tasks

---

## Core Concepts Explained Simply

### What are "Patterns"?
Think of patterns as **conversation starters** for specific tasks:

- `summarize` â†’ "Make this long text short and clear"
- `extract_ideas` â†’ "Find the interesting insights in this content"
- `explain_code` â†’ "Help me understand what this code does"
- `test` â†’ "Check if I understand this concept correctly"

### What is a "Provider"?
Providers are **different AI brains** you can use:

- `ollama` â†’ **Your Local AI** (runs entirely on your computer)
- `claude` â†’ **Deep Thinking AI** (for complex problems)
- `gemini` â†’ **Research & Knowledge AI** (for learning new things)
- `codex` â†’ **Meta-Tool** (orchestrates other AIs for tasks)

### Why "Local-First"?
**GitHub** = just a **storage locker** for code
**Your Computer** = where the **real work happens**

When you use fabric-lite:
1. AI tools run on YOUR machine
2. Your conversations stay private
3. You have full control
4. No one can access your data

---

## Everyday Use Cases - Real Examples

### ğŸ“š Students: Homework Help

```bash
# Summarize a long article
./bin/fabric-lite run --pattern summarize --provider ollama < chapter_text.txt

# Explain difficult concepts
./bin/fabric-lite run --pattern explain_code --provider ollama << 'EOF'
Can you explain photosynthesis like I'm 12 years old?
EOF

# Extract study ideas from notes
./bin/fabric-lite run --pattern extract_ideas --provider ollama < lecture_notes.txt
```

### ğŸ’¼ Professionals: Daily Work Tasks

```bash
# Quick meeting summary
./bin/fabric-lite run --pattern summarize --provider ollama << 'EOF'
Meeting discussed Q3 targets:
- Product launch delayed by 2 weeks
- Marketing budget increased by 15%
- Technical debt needs addressing before next release

Please provide a 3-point summary for executives.
EOF

# Generate project ideas
./bin/fabric-lite run --pattern extract_ideas --provider ollama << 'EOF'
Our current product limitations:
- Limited to English language
- No mobile support
- High pricing tier complaints
- Manual setup process

What are 3 innovative solutions we could implement?
EOF

# Explain technical specifications
./bin/fabric-lite run --pattern explain_code --provider ollama << 'EOF'
Review this API integration code and explain how authentication works:
[Paste complex code here]
EOF
```

### ğŸ§  Researchers: Learning & Analysis

```bash
# Analyze research papers
./bin/fabric-lite run --pattern summarize --provider ollama < research_paper.pdf

# Compare multiple documents
./bin/fabric-lite run --pattern extract_ideas --provider ollama << 'EOF'
Compare these two research methodologies and identify key differences:
[Document 1 summary]
[Document 2 summary]
EOF

# Generate literature reviews
./bin/fabric-lite run --pattern explain_code --provider ollama << 'EOF'
Explain this scientific methodology and suggest improvements:
[Paste methodology section]
EOF
```

### ğŸ¨ Creatives: Content Creation

```bash
# Brainstorm campaign ideas
./bin/fabric-lite run --pattern extract_ideas --provider ollama << 'EOF'
I need creative campaign ideas for:
- Sustainable fashion brand
- Target audience: Gen Z consumers
- Budget: Under $50,000
- Unique selling proposition: Eco-friendly materials

Generate 5 distinct campaign concepts.
EOF

# Write marketing copy
./bin/fabric-lite run --pattern summarize --provider ollama << 'EOF'
Transform these product features into compelling marketing copy:
- All-natural sleep aid
- 8+ hours of uninterrupted sleep
- No grogginess guarantee
- Premium eco-friendly materials

Target audience: Professionals 25-45 who value quality sleep.
EOF

# Improve existing content
./bin/fabric-lite run --pattern explain_code --provider ollama << 'EOF'
Analyze this blog post and suggest 3 improvements:
[Paste blog post here]
EOF
```

---

## Advanced Features - When You're Ready

### ğŸ”„ Saving Conversations
```bash
# Save your AI session
./bin/fabric-lite run --pattern summarize --provider ollama --save-session < document.txt

# Sessions are saved in ~/.config/fabric-lite/sessions/
# Use --resume to continue later
```

### ğŸŒŠ Streaming Responses
```bash
# See responses as they're generated (faster)
./bin/fabric-lite run --pattern summarize --stream --provider ollama < long_document.txt
```

### ğŸ› Choosing Your AI Model
```bash
# Use different models for different tasks
./bin/fabric-lite run --pattern explain_code --model llama3:2 --provider ollama  # Fast
./bin/fabric-lite run --pattern summarize --model llama3:8b --provider ollama  # Smarter
./bin/fabric-lite run --pattern extract_ideas --model mistral --provider ollama  # Creative
```

---

## Troubleshooting - Simple Solutions

### âŒ "Ollama model not found"
```bash
# Download a model first
ollama pull llama3.2

# Try again
./bin/fabric-lite run --pattern summarize --provider ollama < text.txt
```

### âŒ "fabric-lite command not found"
```bash
# Check if you're in right directory
ls -la bin/fabric-lite

# Add to PATH if needed
echo 'export PATH="'$(pwd)'/bin:$PATH"' >> ~/.bashrc
source ~/.bashrc

# Or install system-wide
sudo cp bin/fabric-lite /usr/local/bin/
```

### âŒ "Response is very slow"
```bash
# Use a smaller, faster model
./bin/fabric-lite run --pattern summarize --model llama3:2 --provider ollama < text.txt

# Or get more RAM if you can
ollama pull mistral  # Smaller, faster model
```

### âŒ "Gemini/Claude tools not working"
```bash
# These are separate tools you install if you want them
# But fabric-lite works great with just Ollama!

./bin/fabric-lite run --pattern summarize --provider ollama < text.txt  # This works!
```

---

## Tips & Tricks - Work Like a Pro

### âš¡ Speed Up Your Workflow
```bash
# Create shortcuts in your shell
alias fl='./bin/fabric-lite'
alias sum='fl --pattern summarize --provider ollama'
alias explain='fl --pattern explain_code --provider ollama'
alias ideas='fl --pattern extract_ideas --provider ollama'

# Now just type:
sum < long_file.txt
explain < confusing_code.py
ideas < brainstorm_notes.txt
```

### ğŸ“ Process Multiple Files
```bash
# Summarize all text files in a directory
for file in *.txt; do
  echo "Processing $file..."
  ./bin/fabric-lite run --pattern summarize --provider ollama < "$file" > "${file%.txt}_summary.txt"
done

# Combine everything into one summary
cat *_summary.txt | ./bin/fabric-lite run --pattern summarize --provider ollama > final_summary.txt
```

### ğŸ¯ Pattern Chaining
```bash
# Use AI output as input to next pattern
./bin/fabric-lite run --pattern extract_ideas --provider ollama < project_notes.txt | \
./bin/fabric-lite run --pattern summarize --provider ollama | \
./bin/fabric-lite run --pattern explain_code --provider ollama > final_analysis.txt
```

---

## Your AI Journey Continues

### ğŸŒŸ Next Steps When You're Comfortable

1. **Try All Patterns**: Experiment with summarize, extract_ideas, explain_code, test
2. **Mix Providers**: Test different AI models for different tasks
3. **Create Custom Patterns**: Design your own task-specific templates
4. **Batch Processing**: Use shell scripting to process multiple documents
5. **Explore Features**: Try streaming, sessions, and advanced options

### ğŸ“ Learning Resources

- **Pattern Library**: `./bin/fabric-lite list` to see all available patterns
- **Help System**: `./bin/fabric-lite --help` for all options
- **Community**: Join discussions and share your experiences
- **Project Updates**: Check for new patterns and features

### ğŸ† Success Mindset

- **Start Small**: Don't try to do everything at once
- **Experiment**: Try different approaches and learn what works
- **Iterate**: Build on successful workflows
- **Share**: Help others learn from your experience

---

## Technical Details (Optional Advanced Reading)

### Architecture Overview
- **CLI Entry Point**: `cmd/fabric-lite/` - Your command interface
- **Core Logic**: `internal/` - The AI processing engine
- **Pattern System**: `patterns/` - Template library for tasks
- **Provider Abstraction**: `providers/` - Unified AI tool interface

### Configuration System
- **Global Config**: `~/.config/fabric-lite/config.yaml`
- **Provider Configs**: `~/.config/fabric-lite/providers.yaml`
- **Environment Variables**: `FABRIC_LITE_*` for overrides

### For Developers
- **Add Patterns**: Create new templates in `patterns/your-pattern/`
- **Provider Plugins**: Implement new AI tool integrations
- **Custom Tools**: Build specialized command-line tools

---

## Safety & Privacy

### ğŸ”’ Your Privacy Matters
- **Local Processing**: All AI operations happen on your machine
- **No Cloud Uploads**: Your conversations never leave your computer
- **No Tracking**: We don't monitor or analyze your usage
- **Data Control**: You decide what to save or delete

### ğŸ›¡ï¸ Best Practices
- **Review AI Outputs**: Always check AI-generated content for accuracy
- **Sensitive Information**: Avoid sharing personal data in prompts
- **Regular Updates**: Keep fabric-lite updated for latest features
- **Secure Installation**: Always download from official GitHub repository

---

## Congratulations! ğŸ‰

**You now have everything you need to:**
âœ… Use AI tools privately and securely  
âœ… Solve real problems with AI assistance  
âœ… Learn and explore with AI guidance  
âœ… Create better work with AI collaboration  
âœ… Work more efficiently with AI-powered workflows  

**Remember**: Your AI journey is unique. Start simple, experiment often, and don't hesitate to try new approaches. The most powerful AI setup is the one that works consistently for YOUR needs.

**Happy AI assisting!** ğŸš€

---

*This manual covers everything from first-time setup to advanced usage. Start with Chapter 1 and progress at your own pace.*